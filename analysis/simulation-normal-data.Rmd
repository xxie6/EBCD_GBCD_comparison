---
title: "simulation-normal-data"
author: "Annie Xie"
date: "2024-04-22"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

# Introduction

The Stephens Lab has proposed two different ways of performing orthogonal matrix factorization, Generalized Binary Covariance Decomposition (GBCD) and Empirical Bayes Covariance Decomposition (EBCD). In this analysis, I want to compare these two methods on simulated data with normal noise. The motivation for this analysis comes from the observation that EBCD sometimes behaves unexpectedly on simulated single-cell RNAseq data. I wondered if the unexpected behavior was due to model misspecification and perhaps a lack of robustness for this in the EBCD method. Therefore, I wanted to simulate data from the true model that EBCD fits, and see if we still get any weird behavior. I also want to compare how similar (and different) the EBCD and GBCD results are.

# Code for Simulated Data

```{r, eval = FALSE}
##################################### simulate the single cell RNA-seq data for 20 replicates ##################################################
### simulate normal data
# note to self: I could take the L and F from previous data matrix and add normal random noise to LF'
for(iter in 1:1){
  
  ### set the seed
  set.seed(iter)
  
  ### simulate L
  L <- matrix(0, nrow=1600, ncol=11)
  L[1:800, 1] <- 1
  L[801:1600, 2] <- 1
  L[sample(1:nrow(L), 600, replace=FALSE), 3] <- runif(600, min=0.4, max=2)
  L[1:200, 4] <- 1
  L[201:400, 5] <- 1
  L[401:600, 6] <- 1
  L[601:800, 7] <- 1
  L[801:1000, 8] <- 1
  L[1001:1200, 9] <- 1
  L[1201:1400, 10] <- 1
  L[1401:1600, 11] <- 1
  
  ### simulate F
  F <- matrix(0, nrow=5000, ncol=11)
  F[1:75, 1] <- pmax(rnorm(75, log2(3), 0.5), log2(1.5))
  F[76:150, 2] <- pmax(rnorm(75, log2(3), 0.5), log2(1.5))
  F[251:500, 3] <- pmax(rnorm(250, log2(3), 0.5), log2(1.5))
  F[501:1000, 4] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[1001:1500, 5] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[1501:2000, 6] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[2001:2500, 7] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[2501:3000, 8] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[3001:3500, 9] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[3501:4000, 10] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  F[4001:4500, 11] <- pmax(rnorm(500, log2(3), 0.5), log2(1.5))
  
  ### add normal noise
  E <- matrix(rnorm(nrow(L)*nrow(F), mean = 0, sd = 1), ncol = nrow(F))
  Y = L %*% t(F) + E
  
  ### save the simulated data
  data <- list(Y = Y, L = L, F = F)
  saveRDS(data, file=paste0("data/iter", iter, "_normal_data.rds"))
  rm(data, L, F, Y, E)
}
```

# Package and Functions for Analyses

```{r}
library(ggplot2)
library(cowplot)
library(RColorBrewer)
library(ggrepel)
library(pheatmap)
library(gridExtra)
#library(Seurat)
library(Matrix)
library(ebnm)
library(flashier)
library(magrittr)
library(ashr)
library(irlba)
library(reshape2)

library(patchwork)
library(fastTopics)
source("~/Documents/PhD 3/Research/EBCD/gbcd-workflow/code/fit_cov_ebnmf.R")
```

```{r}
plot_heatmap <- function(L, title = ""){
  ### define the color map
  cols <- colorRampPalette(c("gray96", "red"))(49)
  brks <- seq(min(L), max(L), length=50)
  
  plt <- pheatmap(L, show_rownames = FALSE, show_colnames = FALSE, cluster_rows = FALSE, cluster_cols = FALSE, color = cols, breaks = brks, main = title)
  return(plt)
}
```

```{r}
source("~/Documents/PhD 3/Research/EBCD/ebcd_functions.R")
source("~/Documents/PhD 3/Research/EBCD/gbcd_functions.R")
```

# Simulated Dataset

```{r}
### load in the simulated single cell data from this replicate
iter <- 1
data <- readRDS(paste0("~/Desktop/EBCD_GBCD_comparison_data/iter", iter, "_normal_data.rds"))
```

This is a heatmap of the loadings matrix:
```{r}
plot_heatmap(data$L)
```

This is a heatmap of the factor matrix:
```{r}
plot_heatmap(data$F)
```

```{r}
observed.vals <- data$Y %*% t(data$Y)/ ncol(data$Y)
```

This is a heatmap of the Gram matrix:
```{r}
plot_heatmap(observed.vals)
```

# GBCD Analysis

## Hypothesis
I think GBCD should be able to recover something close to the true loadings estimate. However, it may not be exact since this loadings matrix is not generated exactly from the model used to create the loadings estimate. GBCD gets an estimate for the loadings matrix by fitting $LL^{T} + \sigma^2 I + E$ to the Gram matrix, where $E$ is normally-distributed random noise. Regardless, I do think that GBCD should recover one factor for each patient effect, one factor for each subtype, and a factor corresponding to the shared GEP. 

## Analysis

This is the code to run the GBCD analysis.
```{r, eval = FALSE}
# I used Kmax = 16. I might want to try with different Kmax?
fit.gbcd <- flash_fit_cov_ebnmf(Y = data$Y, Kmax = 16, prior = ebnm::ebnm_generalized_binary, thres = 0.9, extrapolate = FALSE)
```

I have the results saved, so I will just load the results directly.
```{r}
fit.gbcd <- readRDS(paste0("~/Desktop/EBCD_GBCD_comparison_data/iter", iter, "_normal_data_gbcd.rds"))
```

This is a plot of estimate for $L$:
```{r}
plot_heatmap(fit.gbcd$L)
```

This is code to check if there are any factors that are numerically zero. (This is something that I've seen happen in other estimates.) I feel like it would make sense for GBCD to remove loadings that correspond to numerically zero factors.
```{r}
sqrt(colSums(fit.gbcd$F$lfc^2))
```

Therefore are four factors that are numerically zero.
```{r}
non_zero_factor_idx <- (sqrt(colSums(fit.gbcd$F$lfc^2)) > 0)
```

This is a heatmap of the loadings that correspond to non-zero factors.
```{r}
plot_heatmap(fit.gbcd$L[,non_zero_factor_idx])
```

## Rescale GBCD loadings estimate

I'm loading in previously saved results.
```{r}
load("~/Desktop/EBCD_GBCD_comparison_data/iter1_normal_data_gbcd_rescale.RData")
```

This is the code to rescale the GBCD estimate. I've loaded in previously saved results.
```{r, eval = FALSE}
fit.gbcd.rescale1 <- flash_fit_cov_ebnmf_fit_laplace(Y = data$Y, Kmax = 16, prior = ebnm::ebnm_generalized_binary, thres = 0.9, extrapolate = FALSE, maxiter = 500, verbose = 1) 

fit.gbcd.rescale2 <- flash_fit_cov_ebnmf_fit_L(dat = fit.gbcd.rescale1$dat, fit.gbcd.rescale1$fit.cov, Y=data$Y, Kmax=16, prior = ebnm::ebnm_generalized_binary, thres = 0.9, extrapolate = FALSE, maxiter = 500, verbose = 1)
```

**LDF Method of Scaling:**
```{r, eval = FALSE}
fit.gbcd.rescale.ldf <- ldf(fit.gbcd.rescale2$fit.cov, type = 'i')

fit.gbcd.rescale.L <- fit.gbcd.rescale.ldf$L %*% diag(sqrt(fit.gbcd.rescale.ldf$D))

thres <- 0.9
k.idx <- which(fit.gbcd.rescale2$corr > thres)
fit.gbcd.rescale.L <- fit.gbcd.rescale.L[,fit.gbcd.rescale2$k.order][,k.idx]
```

## Assess Fit

```{r}
plot_heatmap(fit.gbcd.rescale.L)
```

```{r}
gbcd.rescaled.fitted.vals <- fit.gbcd.rescale.L %*% t(fit.gbcd.rescale.L)
```

```{r}
observed.vals <- data$Y %*% t(data$Y)/ncol(data$Y)
```

```{r}
sum((observed.vals - gbcd.rescaled.fitted.vals)^2) - sum((diag(observed.vals) - diag(gbcd.rescaled.fitted.vals))^2)
```

This is code to plot (a sub-sampple of) fitted values vs. observed values:
```{r}
set.seed(3952)
diag_idx <- seq(1, prod(dim(observed.vals)), length.out = ncol(observed.vals))
off_diag_idx <- setdiff(c(1:prod(dim(observed.vals))), diag_idx) 
samp.vals <- sample(off_diag_idx, size = 100000)
```

```{r}
ggplot(data = NULL, aes(x = c(as.matrix(observed.vals))[samp.vals], y = c(gbcd.rescaled.fitted.vals)[samp.vals])) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

This is a plot of the diagonal entries of the fitted values vs. the diagonal entries of the observed values:
```{r}
ggplot(data = NULL, aes(x = diag(as.matrix(observed.vals)), y = diag(gbcd.rescaled.fitted.vals))) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

```{r}
gbcd.rescaled.withdiag.fitted.vals <- fit.gbcd.rescale.L %*% t(fit.gbcd.rescale.L) + diag(rep(fit.gbcd.rescale2$s2, nrow(fit.gbcd.rescale.L)))
```

```{r}
sum((observed.vals - gbcd.rescaled.withdiag.fitted.vals)^2)
```

```{r}
samp.vals2 <- sample(c(1:prod(dim(observed.vals))), size = 100000)
```

```{r}
ggplot(data = NULL, aes(x = c(as.matrix(observed.vals))[samp.vals2], y = c(gbcd.rescaled.withdiag.fitted.vals)[samp.vals2])) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

## Correlation of GBCD estimate to true loadings matrix

We compute the correlation of the GBCD estimate of the loadings matrix to the true loadings matrix.
```{r}
correlation_GBCD_true <- cor(fit.gbcd$L, data$L)
colnames(correlation_GBCD_true) <- c('Subtype 1 GEP', 'Subtype 2 GEP', 'Shared GEP', paste('Patient', c(1:8)))
```

```{r}
correlation_GBCD_true
```

## Interpretation of GBCD GEPs
Based off of the loadings, factors 2-9 correspond strongly to patient effects. Factor 1 has the highest correlation with the shared GEP from the true loadings matrix. Factor 9 has the highest correlation with the subtype 1 GEP. Factor 10 has the highest correlation with the subtype 2 GEP. However, what is surprising is factors 9 and 10 in the factor matrix are numerically zero. When you take out the factors that are numerically zero, then the only factors left are those that correspond to the patient effects and the shared GEP from the true loadings matrix.

# EBCD Analysis (with true number of factors)

## Hypothesis
EBCD should be able to recover the true loadings matrix since the data was generated from the model that EBCD fits. Therefore, I hypothesize that EBCD will find one factor for each patient effect, one factor for each subtype, and a factor corresponding to the shared GEP.

## Analysis

I'm loading in previously saved results.
```{r}
fit.ebcd <- readRDS(paste0("~/Desktop/EBCD_GBCD_comparison_data/iter", iter, "_normal_data_ebcd.rds"))
```

This is the code to run the EBCD analysis. I've already loaded in the saved results. 
```{r, eval = FALSE}
set.seed(295)
fit.ebcd <- ebcd(X = t(data$Y), Kmax = 12, ebnm_fn = ebnm::ebnm_generalized_binary)
```

This is a plot of the scaled estimate of $L$. This estimate is scaled such that the infinity norm for each column is 1, i.e. the maximum value for each column is 1. 
```{r}
plot_heatmap(t(t(fit.ebcd$EL)/apply(fit.ebcd$EL,2, max)))
```

```{r}
ebcd.fitted.vals <- fit.ebcd$EL %*% t(fit.ebcd$EL)
```

```{r}
sum((observed.vals - ebcd.fitted.vals)^2)
```

```{r}
sum((observed.vals - ebcd.fitted.vals)^2) - sum((diag(observed.vals) - diag(ebcd.fitted.vals))^2)
```

This is a plot of (a subset of) the fitted values vs. observed values:
```{r}
ggplot(data = NULL, aes(x = c(as.matrix(observed.vals))[samp.vals], y = c(ebcd.fitted.vals)[samp.vals])) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

This is a plot of the diagonal entries of the fitted values vs. the diagonal entries of the observed values:
```{r}
ggplot(data = NULL, aes(x = diag(as.matrix(observed.vals)), y = diag(ebcd.fitted.vals))) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

This is a plot of the progression of the objective function
```{r}
ggplot(data = NULL, aes(x = c(1:length(fit.ebcd$vec.obj)), y = fit.ebcd$vec.obj)) + geom_line()
```

This is the number of iterations that the backfit did before the convergence criterion was satisfied:
```{r}
length(fit.ebcd$vec.obj)
```

## Correlation of EBCD estimate to true loadings matrix

We compute the correlation of the EBCD estimate of the loadings matrix to the true loadings matrix.
```{r}
correlation_EBCD_true <- cor(fit.ebcd$EL, data$L)
colnames(correlation_EBCD_true) <- c('Subtype 1 GEP', 'Subtype 2 GEP', 'Shared GEP', paste('Patient', c(1:8)))
```

```{r}
correlation_EBCD_true
```

## Interpretation of EBCD GEPs
Based off of the loadings, factors 3-10 correspond strongly to patient effects. Factor 1 has the highest correlation with the shared GEP from the true loadings matrix with a correlation value of 0.998.

# Comparing GBCD and EBCD

## Correlation between GBCD and EBCD loadings estimates

We analyze the concordance between the loadings matrices from GBCD and EBCD. We compute the correlations between the columns of the GBCD loadings estimate and the columns of the EBCD loadings estimate.  
```{r}
correlation_L_estimates <- cor(fit.gbcd$L, fit.ebcd$EL)
```
  
For each column of the EBCD loadings estimate, we identify the corresponding column of the GBCD loadings estimate that is most highly correlated.  
```{r}
max_corr <- apply(correlation_L_estimates, 2, FUN = max)
return_gep <- function(x){
  gep_index <- which.max(x)
  if (gep_index == 1){
    gep_name <- 'Baseline'
  }
  else{
    gep_name <- paste('GEP',(gep_index - 1))
  }
  return(gep_name)
}
max_gbcd_gep <- apply(correlation_L_estimates, 2, FUN = return_gep)
```

```{r}
gep_colnames <- c('Baseline', paste('GEP', c(1:(ncol(fit.ebcd$EL) - 1))))
correlation_info <- data.frame(max_gbcd_gep, max_corr, row.names = gep_colnames)
print(correlation_info[order(correlation_info$max_corr, decreasing = TRUE), ])
```

## Observations

As previously mentioned, the GBCD method found factors that strongly correspond with the shared GEP, patient-effect GEPs, and subtype-specific GEPs of the true loadings matrix. However, the subtype-specific GEPs are numerically zero in the factor matrix. It was surprising to me that the GBCD method found factors that are numerically zero since GBCD also assumes normally distributed noise -- I'm not exactly sure why it did that in this setting.

The EBCD method found factors that strongly correspond with the shared GEP and patient-effect GEPs from the true loadings matrix. However, the EBCD method did not find any factors that correspond to subtype-specific effects; it found two additional shared effect factors plus a factor corresponding to two patients. I wonder if it would find subtype effects if we fit EBCD with more factors. I also wanted to note that I have done different versions of this experiment, and EBCD did find the subtype effects in those cases. Therefore, I guess EBCD can find the subtype effects, but it may not necessarily always find them (and the goal is to figure out when). In my other experiments, I think I had a larger sample size and larger number of genes, so I wonder if the larger sample size helps the method find the shared effects. The signal to noise ratio in this setting may also make it more difficult to find the subtype GEPs.

I also noticed that the EBCD estimate had a worse fit to the data than the GBCD estimate. I think it might be because the GBCD estimate added more factors while I limited the EBCD estimate to only 12 factors (since the true number of factors is 11).

# Experiment: Use GBCD output to initialize EBCD

## Hypothesis

The main difference between the EBCD estimate and GBCD estimate is the presence of the subtype effects. I'm curious to see if the EBCD backfit will retain the factors that correspond to subtype effects. I think it should since the data is generated with subtype effects. Of course, the subtype effects in the GBCD estimate correspond to factors that are numerically zero. EBCD will not produce numerically zero factors, so I'm guessing the backfit will adjust these factors such that they are not numerically zero.

## Analysis

This is the code to run the analysis. I will load in previously saved results.
```{r, eval = FALSE}
Z.init <- PolarU(fit.ebcd$A%*%fit.gbcd.rescale.L)
fitted.Y <- Z.init%*%t(fit.gbcd.rescale.L)
tau.est <- prod(dim(fit.ebcd$A)) / sum((fit.ebcd$A - fitted.Y)^2)
ebcd_obj_init_rescaled <- list(
    A = fit.ebcd$A, N = fit.ebcd$N, nrowA = fit.ebcd$nrowA,
    tau = tau.est, Z = Z.init, EL = fit.gbcd.rescale.L, ebnm_fn = ebnm::ebnm_generalized_binary
  )
```

```{r, eval = FALSE}
fit.ebcd.gbcd.init_rescaled <- ebcd_backfit(ebcd_obj_init_rescaled, maxiter = 2500)
```

```{r}
load('~/Desktop/EBCD_GBCD_comparison_data/iter1_normal_data_ebcd_gbcd_init.RData')
```

```{r}
#plot initialization
plot_heatmap(fit.gbcd.rescale.L)
```

```{r}
plot_heatmap(t(t(fit.gbcd.rescale.L)/apply(fit.gbcd.rescale.L,2, max)))
```

```{r}
plot_heatmap(t(t(fit.ebcd.gbcd.init_rescaled$EL)/apply(fit.ebcd.gbcd.init_rescaled$EL,2, max)))
```

This is code to check if there are any factors that are numerically zero.
```{r}
sqrt(colSums(fit.ebcd.gbcd.init_rescaled$Z^2))
```

This is the number of backfit iterations that were needed to reach convergence
```{r}
print(length(fit.ebcd.gbcd.init_rescaled$vec.obj))
```

```{r, eval = FALSE}
plot_heatmap(ebcd_backfit(ebcd_obj_init_rescaled, maxiter = 5)$EL)
```

```{r}
ebcd.gbcd.rescaled.init.fitted.vals <- fit.ebcd.gbcd.init_rescaled$EL %*% t(fit.ebcd.gbcd.init_rescaled$EL)
```

```{r}
sum((observed.vals - ebcd.gbcd.rescaled.init.fitted.vals)^2)
```

```{r}
sum((observed.vals - ebcd.gbcd.rescaled.init.fitted.vals)^2) - sum((diag(observed.vals) - diag(ebcd.gbcd.rescaled.init.fitted.vals))^2)
```

This is a plot of (a subset of) the fitted values vs. observed values:
```{r}
ggplot(data = NULL, aes(x = c(as.matrix(observed.vals))[samp.vals], y = c(ebcd.gbcd.rescaled.init.fitted.vals)[samp.vals])) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

This is a plot of the diagonal entries of the fitted values vs. the diagonal entries of the observed values:
```{r}
ggplot(data = NULL, aes(x = diag(as.matrix(observed.vals)), y = diag(ebcd.gbcd.rescaled.init.fitted.vals))) + geom_point() + xlab('Observed Values') + ylab('Fitted Values') + geom_abline(slope = 1, intercept = 0, color = 'red')
```

This is a plot of the progression of the objective function
```{r}
ggplot(data = NULL, aes(x = c(2:length(fit.ebcd.gbcd.init_rescaled$vec.obj)), y = fit.ebcd.gbcd.init_rescaled$vec.obj[-1])) + geom_line()
```

## Correlation to true loadings matrix

```{r}
correlation_EBCD_GBCD_init_true <- cor(fit.ebcd.gbcd.init_rescaled$EL, data$L)

colnames(correlation_EBCD_GBCD_init_true) <- c('Subtype 1 GEP', 'Subtype 2 GEP', 'Shared GEP', paste('Patient', c(1:8)))
```

```{r}
correlation_EBCD_GBCD_init_true
```

## Observations

The EBCD backfit retained a lot of the GBCD estimate. In particular, it kept factor 1 which highly corresponds to the the shared GEP from the true loadings matrix. In addition, the estimate has all of the patient effects as separate factors. The backfit kept most of the integrity of the subtype-specific factors, but it did add some positive loadings to samples not in the respective subtype. The backfit also made the additional shared GEPs a lot more dense (with respect to the loadings).

The fit of this estimate (disregarding the diagonal entries) is better than the fit of the EBCD with greedy initialization estimate. However, it is not as good as the GBCD estimate. 
